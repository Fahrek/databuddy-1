#do not change
aa={'ORAEXA_TimestampTable_withHeader.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_705000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_TimestampTable_withHeader.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_712000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryDir_keepWhitespace.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_328000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'query_sql_dir': ('-Q', '--query_sql_dir', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\query_dir_ora', 'Input dir with Exadata query files sql.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_TimestampTable.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_084000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Table_KeepSpoolFile.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_061000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Partition_NoClient.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_042000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_sub_partition': ('-S', '--from_sub_partition', 'part_15', 'From sub-partition.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', "'(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=localhost)(PORT=1521))(CONNECT_DATA=(SERVER=DEDICATED)(SERVICE_NAME=orcl)))'", 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Partitioned_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_DateTable_Email.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_816000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Date_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_DateTable_Email.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_821000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Date_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_Partition_TruncateTarget_AskToTruncate.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'ask_to_truncate': ('-E', '--ask_to_truncate', 1, 'Ask to truncate.'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_363000', 'Timestamp (log_dir/job_name/timestamp).'), 'truncate_target': ('-U', '--truncate_target', 1, 'Truncate target table/partition/subpartition.'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_sub_partition': ('-S', '--from_sub_partition', 'part_15', 'From sub-partition.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Partitioned_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryDir_trimWhitespace.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_568000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'query_sql_dir': ('-Q', '--query_sql_dir', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\query_dir_ora', 'Input dir with Exadata query files sql.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_ShardedQueryDir_withHeader.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_055000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'query_sql_dir': ('-Q', '--query_sql_dir', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\query_dir_ora', 'Input dir with Exadata query files sql.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_DateTable.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_390000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Date_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_Table_withHeader.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_687000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Table_KeepSpoolFile.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_067000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_PartitionList.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_792000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'from_table': ('-c', '--from_table', 'SCOTT.Partitioned_test_from', 'From table.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_user': ('-j', '--from_user', 'part_13,part_14,part_15,part_16', 'Exadata source user.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryDir_withHeader.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_148000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'query_sql_dir': ('-Q', '--query_sql_dir', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\query_dir_ora', 'Input dir with Exadata query files sql.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_TimezoneQueryFile.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_250000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'query_sql_file': ('-q', '--query_sql_file', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\oracle_query.sql', 'Input file with Exadata query sql.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_TimestampTable_trimWhitespace.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_121000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Parallel_SubpartitionList.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 3, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_947000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_db_name': ('-b', '--from_db_name', 'part_15_sp1,part_10_sp2,part_14_sp1,part_14_sp2', 'Exadata source database.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Sub_Partitioned_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_Subpartition.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_887000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Sub_Partitioned_test_from', 'From table.'), 'from_passwd': ('-x', '--from_passwd', 'part_15_sp1', 'Exadata source user password.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryFile_keepWhitespace_noHeader.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_964000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'query_sql_file': ('-q', '--query_sql_file', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\oracle_query.sql', 'Input file with Exadata query sql.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Parallel_PartitionList.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 3, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_671000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'from_table': ('-c', '--from_table', 'SCOTT.Partitioned_test_from', 'From table.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_user': ('-j', '--from_user', 'part_13,part_14,part_15,part_16', 'Exadata source user.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_JSON_Table.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'json', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_658000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Partition_KeepSpoolFile.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_774000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_sub_partition': ('-S', '--from_sub_partition', 'part_15', 'From sub-partition.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Partitioned_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryDir_WithWideRows.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'column_buckets': ('-0', '--column_buckets', 2, 'Wide row support.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_005000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'query_sql_dir': ('-Q', '--query_sql_dir', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\query_dir_ora', 'Input dir with Exadata query files sql.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_TimezoneQueryFile.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_246000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'query_sql_file': ('-q', '--query_sql_file', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\oracle_query.sql', 'Input file with Exadata query sql.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Subpartition_KeepSpoolFile.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_255000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Sub_Partitioned_test_from', 'From table.'), 'from_passwd': ('-x', '--from_passwd', 'part_15_sp1', 'Exadata source user password.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryFile_keepWhitespace_noHeader.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_974000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'query_sql_file': ('-q', '--query_sql_file', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\oracle_query.sql', 'Input file with Exadata query sql.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryFile_WithWideRows.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'column_buckets': ('-0', '--column_buckets', 2, 'Wide row support.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_510000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'query_sql_file': ('-q', '--query_sql_file', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\oracle_query.sql', 'Input file with Exadata query sql.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Table.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_855000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_DateTable_JobName.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_982000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'FROM_ORAEXA_DateTable_JobName_TO_MONGO_Collection', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Date_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Subpartition_keepWhitespace.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_797000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Sub_Partitioned_test_from', 'From table.'), 'from_passwd': ('-x', '--from_passwd', 'part_15_sp1', 'Exadata source user password.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Partition_WithWideRows.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'column_buckets': ('-0', '--column_buckets', 2, 'Wide row support.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_466000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_sub_partition': ('-S', '--from_sub_partition', 'part_15', 'From sub-partition.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Partitioned_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryFile_withHeader.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_337000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'query_sql_file': ('-q', '--query_sql_file', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\oracle_query.sql', 'Input file with Exadata query sql.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryFile.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_830000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'query_sql_file': ('-q', '--query_sql_file', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\oracle_query.sql', 'Input file with Exadata query sql.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Subpartition_keepWhitespace.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_807000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Sub_Partitioned_test_from', 'From table.'), 'from_passwd': ('-x', '--from_passwd', 'part_15_sp1', 'Exadata source user password.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_Subpartition_keepWhitespace.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_802000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Sub_Partitioned_test_from', 'From table.'), 'from_passwd': ('-x', '--from_passwd', 'part_15_sp1', 'Exadata source user password.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryFile_keepWhitespace_withHeader.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_956000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'query_sql_file': ('-q', '--query_sql_file', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\oracle_query.sql', 'Input file with Exadata query sql.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Partition_NoClient.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_033000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_sub_partition': ('-S', '--from_sub_partition', 'part_15', 'From sub-partition.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', "'(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=localhost)(PORT=1521))(CONNECT_DATA=(SERVER=DEDICATED)(SERVICE_NAME=orcl)))'", 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Partitioned_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Partition_trimWhitespace.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_346000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_sub_partition': ('-S', '--from_sub_partition', 'part_15', 'From sub-partition.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Partitioned_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Partition_trimWhitespace.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_358000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_sub_partition': ('-S', '--from_sub_partition', 'part_15', 'From sub-partition.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Partitioned_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_Parallel_TableList.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 3, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_917000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_partition': ('-P', '--from_partition', 'SCOTT.Timestamp_test_from,SCOTT.Timestamp_test_from_2', 'From partition.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Partition_Validate.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_112000', 'Timestamp (log_dir/job_name/timestamp).'), 'validate': ('-V', '--validate', 1, 'Check if source and target objects exist.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_sub_partition': ('-S', '--from_sub_partition', 'part_15', 'From sub-partition.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Partitioned_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryFile.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_825000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'query_sql_file': ('-q', '--query_sql_file', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\oracle_query.sql', 'Input file with Exadata query sql.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryFile_trimWhitespace_withHeader.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_846000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'query_sql_file': ('-q', '--query_sql_file', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\oracle_query.sql', 'Input file with Exadata query sql.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_ShardedTable.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_604000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_TableList.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_206000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_partition': ('-P', '--from_partition', 'SCOTT.Timestamp_test_from,SCOTT.Timestamp_test_from_2', 'From partition.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryFile_WithWideRows.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'column_buckets': ('-0', '--column_buckets', 2, 'Wide row support.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_514000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'query_sql_file': ('-q', '--query_sql_file', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\oracle_query.sql', 'Input file with Exadata query sql.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_Partition_NoClient.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_037000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_sub_partition': ('-S', '--from_sub_partition', 'part_15', 'From sub-partition.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', "'(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=localhost)(PORT=1521))(CONNECT_DATA=(SERVER=DEDICATED)(SERVICE_NAME=orcl)))'", 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Partitioned_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_ShardedSubpartition.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_623000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Sub_Partitioned_test_from', 'From table.'), 'from_passwd': ('-x', '--from_passwd', 'part_15_sp1', 'Exadata source user password.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryDir_withHeader.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_153000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'query_sql_dir': ('-Q', '--query_sql_dir', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\query_dir_ora', 'Input dir with Exadata query files sql.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryFile_trimWhitespace_noHeader.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_434000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'query_sql_file': ('-q', '--query_sql_file', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\oracle_query.sql', 'Input file with Exadata query sql.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_TimestampTable_withComaHeader.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_645000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_Partition_withHeader.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_494000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_sub_partition': ('-S', '--from_sub_partition', 'part_15', 'From sub-partition.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Partitioned_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryFile_noHeader.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_879000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'query_sql_file': ('-q', '--query_sql_file', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\oracle_query.sql', 'Input file with Exadata query sql.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryFile_trimWhitespace_withHeader.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_851000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'query_sql_file': ('-q', '--query_sql_file', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\oracle_query.sql', 'Input file with Exadata query sql.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_Partition_WithWideRows.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'column_buckets': ('-0', '--column_buckets', 2, 'Wide row support.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_461000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_sub_partition': ('-S', '--from_sub_partition', 'part_15', 'From sub-partition.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Partitioned_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_TimestampTable_withHeader.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_719000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_ShardedQueryDir.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_744000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'query_sql_dir': ('-Q', '--query_sql_dir', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\query_dir_ora', 'Input dir with Exadata query files sql.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Partition_KeepSpoolFile.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_768000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_sub_partition': ('-S', '--from_sub_partition', 'part_15', 'From sub-partition.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Partitioned_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryFile_keepWhitespace_withHeader.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_960000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'query_sql_file': ('-q', '--query_sql_file', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\oracle_query.sql', 'Input file with Exadata query sql.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_TimezoneTable.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_485000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timezone_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_Table_KeepSpoolFile.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_072000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_Partition_WithWideRows.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'column_buckets': ('-0', '--column_buckets', 2, 'Wide row support.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_472000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_sub_partition': ('-S', '--from_sub_partition', 'part_15', 'From sub-partition.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Partitioned_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_ShardedQueryDir_withHeader.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_047000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'query_sql_dir': ('-Q', '--query_sql_dir', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\query_dir_ora', 'Input dir with Exadata query files sql.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Partition_Validate.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_117000', 'Timestamp (log_dir/job_name/timestamp).'), 'validate': ('-V', '--validate', 1, 'Check if source and target objects exist.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_sub_partition': ('-S', '--from_sub_partition', 'part_15', 'From sub-partition.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Partitioned_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryFile_trimWhitespace.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_193000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'query_sql_file': ('-q', '--query_sql_file', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\oracle_query.sql', 'Input file with Exadata query sql.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_DateTable_JobName.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_987000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'FROM_ORAEXA_DateTable_JobName_TO_MONGO_Collection_3_insertionWorkers', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Date_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryDir_WithWideRows.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'column_buckets': ('-0', '--column_buckets', 2, 'Wide row support.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_014000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'query_sql_dir': ('-Q', '--query_sql_dir', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\query_dir_ora', 'Input dir with Exadata query files sql.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_Table_withHeader.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_699000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryFile_trimWhitespace_noHeader.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_439000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'query_sql_file': ('-q', '--query_sql_file', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\oracle_query.sql', 'Input file with Exadata query sql.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryDir.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_537000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'query_sql_dir': ('-Q', '--query_sql_dir', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\query_dir_ora', 'Input dir with Exadata query files sql.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_TimestampTable_keepWhitespace_Validate.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_907000', 'Timestamp (log_dir/job_name/timestamp).'), 'validate': ('-V', '--validate', 1, 'Check if source and target objects exist.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_TimestampTable.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_077000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_TableList.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_202000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_partition': ('-P', '--from_partition', 'SCOTT.Timestamp_test_from,SCOTT.Timestamp_test_from_2', 'From partition.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryFile_keepWhitespace_withHeader.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_952000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'query_sql_file': ('-q', '--query_sql_file', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\oracle_query.sql', 'Input file with Exadata query sql.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_TimestampTable_keepWhitespace_withHeader.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_233000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_ShardedTimestampTable_keepWhitespace_Validate.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_528000', 'Timestamp (log_dir/job_name/timestamp).'), 'validate': ('-V', '--validate', 1, 'Check if source and target objects exist.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_ShardedPartition.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_547000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_sub_partition': ('-S', '--from_sub_partition', 'part_15', 'From sub-partition.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Partitioned_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_TimezoneTable.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_476000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timezone_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_TimestampTable_keepWhitespace_Validate.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_897000', 'Timestamp (log_dir/job_name/timestamp).'), 'validate': ('-V', '--validate', 1, 'Check if source and target objects exist.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Partition_Validate.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_107000', 'Timestamp (log_dir/job_name/timestamp).'), 'validate': ('-V', '--validate', 1, 'Check if source and target objects exist.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_sub_partition': ('-S', '--from_sub_partition', 'part_15', 'From sub-partition.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Partitioned_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Partition_keepWhitespace.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_310000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_sub_partition': ('-S', '--from_sub_partition', 'part_15', 'From sub-partition.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Partitioned_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryDir_keepWhitespace_withHeader.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_019000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'query_sql_dir': ('-Q', '--query_sql_dir', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\query_dir_ora', 'Input dir with Exadata query files sql.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_TimestampTable_keepWhitespace_Validate.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_902000', 'Timestamp (log_dir/job_name/timestamp).'), 'validate': ('-V', '--validate', 1, 'Check if source and target objects exist.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Partition_KeepSpoolFile.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_761000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_sub_partition': ('-S', '--from_sub_partition', 'part_15', 'From sub-partition.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Partitioned_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_TimestampTable_keepWhitespace_withHeader.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_229000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Subpartition.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_883000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Sub_Partitioned_test_from', 'From table.'), 'from_passwd': ('-x', '--from_passwd', 'part_15_sp1', 'Exadata source user password.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Table_WithWideRows.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'column_buckets': ('-0', '--column_buckets', 2, 'Wide row support.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_930000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_TimezoneTable_KeepSpoolFile.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_420000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timezone_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Parallel_SubpartitionList.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 3, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_939000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_db_name': ('-b', '--from_db_name', 'part_15_sp1,part_10_sp2,part_14_sp1,part_14_sp2', 'Exadata source database.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Sub_Partitioned_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryDir_WithWideRows.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'column_buckets': ('-0', '--column_buckets', 2, 'Wide row support.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_010000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'query_sql_dir': ('-Q', '--query_sql_dir', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\query_dir_ora', 'Input dir with Exadata query files sql.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Subpartition_KeepSpoolFile.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_259000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Sub_Partitioned_test_from', 'From table.'), 'from_passwd': ('-x', '--from_passwd', 'part_15_sp1', 'Exadata source user password.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Table_WithWideRows.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'column_buckets': ('-0', '--column_buckets', 2, 'Wide row support.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_934000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryDir_trimWhitespace.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_576000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'query_sql_dir': ('-Q', '--query_sql_dir', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\query_dir_ora', 'Input dir with Exadata query files sql.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_PartitionList.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_786000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'from_table': ('-c', '--from_table', 'SCOTT.Partitioned_test_from', 'From table.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_user': ('-j', '--from_user', 'part_13,part_14,part_15,part_16', 'Exadata source user.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Subpartition.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_891000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Sub_Partitioned_test_from', 'From table.'), 'from_passwd': ('-x', '--from_passwd', 'part_15_sp1', 'Exadata source user password.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_Parallel_SubpartitionList.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 3, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_943000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_db_name': ('-b', '--from_db_name', 'part_15_sp1,part_10_sp2,part_14_sp1,part_14_sp2', 'Exadata source database.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Sub_Partitioned_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryDir_trimWhitespace.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_562000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'query_sql_dir': ('-Q', '--query_sql_dir', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\query_dir_ora', 'Input dir with Exadata query files sql.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryFile_keepWhitespace.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_220000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'query_sql_file': ('-q', '--query_sql_file', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\oracle_query.sql', 'Input file with Exadata query sql.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_TimestampTable_trimWhitespace.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_125000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Parallel_ShardedTable.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 3, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_738000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_ShardedTable.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_613000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_Partition_withHeader.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_500000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_sub_partition': ('-S', '--from_sub_partition', 'part_15', 'From sub-partition.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Partitioned_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_Subpartition_WithWideRows.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'column_buckets': ('-0', '--column_buckets', 2, 'Wide row support.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_134000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Sub_Partitioned_test_from', 'From table.'), 'from_passwd': ('-x', '--from_passwd', 'part_15_sp1', 'Exadata source user password.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_TimestampTable.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_090000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_ShardedTimestampTable_keepWhitespace_Validate.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_523000', 'Timestamp (log_dir/job_name/timestamp).'), 'validate': ('-V', '--validate', 1, 'Check if source and target objects exist.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_DateTable.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_378000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Date_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Subpartition_WithWideRows.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'column_buckets': ('-0', '--column_buckets', 2, 'Wide row support.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_142000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Sub_Partitioned_test_from', 'From table.'), 'from_passwd': ('-x', '--from_passwd', 'part_15_sp1', 'Exadata source user password.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_Partition_keepWhitespace.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_314000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_sub_partition': ('-S', '--from_sub_partition', 'part_15', 'From sub-partition.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Partitioned_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryFile_withHeader.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_341000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'query_sql_file': ('-q', '--query_sql_file', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\oracle_query.sql', 'Input file with Exadata query sql.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_Parallel_ShardedTable.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 3, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_726000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryFile.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_836000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'query_sql_file': ('-q', '--query_sql_file', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\oracle_query.sql', 'Input file with Exadata query sql.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_Partition_withHeader.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_490000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_sub_partition': ('-S', '--from_sub_partition', 'part_15', 'From sub-partition.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Partitioned_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_TimestampTable_withComaHeader.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_634000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryFile_trimWhitespace.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_197000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'query_sql_file': ('-q', '--query_sql_file', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\oracle_query.sql', 'Input file with Exadata query sql.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_ShardedQueryDir.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_754000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'query_sql_dir': ('-Q', '--query_sql_dir', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\query_dir_ora', 'Input dir with Exadata query files sql.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_Parallel_TableList.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 3, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_921000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_partition': ('-P', '--from_partition', 'SCOTT.Timestamp_test_from,SCOTT.Timestamp_test_from_2', 'From partition.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_JSON_Table.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'json', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_651000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_ShardedSubpartition.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_618000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Sub_Partitioned_test_from', 'From table.'), 'from_passwd': ('-x', '--from_passwd', 'part_15_sp1', 'Exadata source user password.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Parallel_TableList.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 3, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_912000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_partition': ('-P', '--from_partition', 'SCOTT.Timestamp_test_from,SCOTT.Timestamp_test_from_2', 'From partition.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_SubpartitionList.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_448000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_db_name': ('-b', '--from_db_name', 'part_15_sp1,part_15_sp2,part_14_sp1,part_14_sp2', 'Exadata source database.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Sub_Partitioned_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryFile_noHeader.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_874000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'query_sql_file': ('-q', '--query_sql_file', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\oracle_query.sql', 'Input file with Exadata query sql.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryDir_keepWhitespace.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_319000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'query_sql_dir': ('-Q', '--query_sql_dir', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\query_dir_ora', 'Input dir with Exadata query files sql.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryDir.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_542000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'query_sql_dir': ('-Q', '--query_sql_dir', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\query_dir_ora', 'Input dir with Exadata query files sql.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_ShardedPartition.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_552000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_sub_partition': ('-S', '--from_sub_partition', 'part_15', 'From sub-partition.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Partitioned_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Subpartition_Validate.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_183000', 'Timestamp (log_dir/job_name/timestamp).'), 'validate': ('-V', '--validate', 1, 'Check if source and target objects exist.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Sub_Partitioned_test_from', 'From table.'), 'from_passwd': ('-x', '--from_passwd', 'part_15_sp1', 'Exadata source user password.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_DateTable_JobName.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_978000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'FROM_ORAEXA_DateTable_JobName_TO_MONGO_Collection_Upsert', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Date_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Partition_trimWhitespace.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_350000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_sub_partition': ('-S', '--from_sub_partition', 'part_15', 'From sub-partition.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Partitioned_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryFile_trimWhitespace.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_188000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'query_sql_file': ('-q', '--query_sql_file', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\oracle_query.sql', 'Input file with Exadata query sql.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Table_withHeader.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_693000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryDir_keepWhitespace_withHeader.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_023000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'query_sql_dir': ('-Q', '--query_sql_dir', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\query_dir_ora', 'Input dir with Exadata query files sql.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Subpartition_Validate.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_175000', 'Timestamp (log_dir/job_name/timestamp).'), 'validate': ('-V', '--validate', 1, 'Check if source and target objects exist.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Sub_Partitioned_test_from', 'From table.'), 'from_passwd': ('-x', '--from_passwd', 'part_15_sp1', 'Exadata source user password.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryDir_withHeader.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_158000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'query_sql_dir': ('-Q', '--query_sql_dir', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\query_dir_ora', 'Input dir with Exadata query files sql.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_Partition_TruncateTarget_AskToTruncate.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'ask_to_truncate': ('-E', '--ask_to_truncate', 1, 'Ask to truncate.'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_368000', 'Timestamp (log_dir/job_name/timestamp).'), 'truncate_target': ('-U', '--truncate_target', 1, 'Truncate target table/partition/subpartition.'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_sub_partition': ('-S', '--from_sub_partition', 'part_15', 'From sub-partition.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Partitioned_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'default': [{'ask_to_truncate': ['-E', '--ask_to_truncate', '', 'Ask to truncate.'], 'shard_pre_etl': ['-2', '--shard_pre_etl', '', 'Path to shard level pre-ETL Python script.'], 'debug_level': ['-dbg', '--debug_level', '', 'QC Debug level.'], 'spool_type': ['-6', '--spool_type', '', 'Spool file type (CSV or JSON).'], 'keep_data_file': ['-K', '--keep_data_file', '', 'Keep data dump.'], 'default_spool_dir': ['-F', '--default_spool_dir', '', 'Default data dump dir (default_spool_dir/job_name/timestamp).'], 'lame_duck': ['-l', '--lame_duck', '', 'Limit rows (lame duck run).'], 'copy_vector': ['-w', '--copy_vector', '', 'Data copy direction.'], 'log_dir': ['-M', '--log_dir', '', 'Log destination.'], 'time_stamp': ['-Y', '--time_stamp', '', 'Timestamp (log_dir/job_name/timestamp).'], 'job_name': ['-B', '--job_name', '', 'Job name (log_dir/job_name).'], 'status_pipe_id': ['-spID', '--status_pipe_id', '', 'Status reporting pipe ID.'], 'job_pre_etl': ['-1', '--job_pre_etl', '', 'Path to job level pre-ETL Python script.'], 'num_of_shards': ['-r', '--num_of_shards', '', 'Number of shards.'], 'loader_profile': ['-C', '--loader_profile', '', 'SQL*Loader profile (user defined).'], 'email_to': ['-L', '--email_to', '', 'Email job status.'], 'host_map': ['-5', '--host_map', '', 'Host-to-shard map.'], 'validate': ['-V', '--validate', '', 'Check if source and target objects exist.'], 'field_term': ['-t', '--field_term', '', 'Field terminator.'], 'pool_size': ['-ps', '--pool_size', '', 'Pool size.'], 'column_buckets': ['-0', '--column_buckets', '', 'Wide row support.'], 'job_post_etl': ['-3', '--job_post_etl', '', 'Jobs post-etl script.'], 'truncate_target': ['-U', '--truncate_target', '', 'Truncate target table/partition/subpartition.'], 'shard_post_etl': ['-4', '--shard_post_etl', '', 'Shards post-etl script.'], 'key_on_exit': ['-X', '--key_on_exit', '', 'Ask for an "Enter" key upon exit.']}, {'query_sql_file': ['-q', '--query_sql_file', '', 'Input file with Exadata query sql.'], 'from_db_name': ['-b', '--from_db_name', '', 'Exadata source database.'], 'from_partition': ['-P', '--from_partition', '', 'From partition.'], 'from_sub_partition': ['-S', '--from_sub_partition', '', 'From sub-partition.'], 'header': ['-A', '--header', '', 'Include header to Exadata extract.'], 'from_table': ['-c', '--from_table', '', 'From table.'], 'nls_timestamp_format': ['-m', '--nls_timestamp_format', '', 'nls_timestamp_format for source.'], 'nls_date_format': ['-e', '--nls_date_format', '', 'nls_date_format for source.'], 'keep_whitespace': ['-W', '--keep_whitespace', '', 'Keep whitespace from CHAR type in "Exadata" extract.'], 'nls_timestamp_tz_format': ['-O', '--nls_timestamp_tz_format', '', 'nls_timestamp_tz_format for source.'], 'from_user': ['-j', '--from_user', '', 'Exadata source user.'], 'from_passwd': ['-x', '--from_passwd', '', 'Exadata source user password.'], 'query_sql_dir': ['-Q', '--query_sql_dir', '', 'Input dir with Exadata query files sql.']}, {'to_db_name': ['-d', '--to_db_name', '', 'MongoDB database.'], 'to_db_port': ['-T', '--to_db_port', '', 'Target MongoDB port.'], 'to_column_names': ['-Z', '--to_column_names', '', 'To column list for MongoDB.'], 'to_collection': ['-a', '--to_collection', '', 'To table.'], 'to_user': ['-u', '--to_user', '', 'Target MongoDB db user.'], 'to_passwd': ['-p', '--to_passwd', '', 'MongoDB user password.'], 'to_db_server': ['-s', '--to_db_server', '', 'Target MongoDB instance name.'], 'numInsertionWorkers': ['-numIW', '--numInsertionWorkers', '', 'Upsert rows into MongoDB.'], 'upsert': ['-G', '--upsert', '', 'Upsert rows into MongoDB.']}], 'ORAEXA_QueryDir_keepWhitespace_withHeader.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_028000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'query_sql_dir': ('-Q', '--query_sql_dir', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\query_dir_ora', 'Input dir with Exadata query files sql.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_Partition.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_162000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_sub_partition': ('-S', '--from_sub_partition', 'part_15', 'From sub-partition.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Partitioned_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_TimestampTable_withComaHeader.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_639000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryFile_trimWhitespace_withHeader.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_841000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'query_sql_file': ('-q', '--query_sql_file', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\oracle_query.sql', 'Input file with Exadata query sql.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_TableList.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_211000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_partition': ('-P', '--from_partition', 'SCOTT.Timestamp_test_from,SCOTT.Timestamp_test_from_2', 'From partition.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryFile_TableNamedFile.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_996000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'query_sql_file': ('-q', '--query_sql_file', '"C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\SCOTT.TIMESTAMP_TEST_TO.0.sql"', 'Input file with Exadata query sql.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Table_WithWideRows.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'column_buckets': ('-0', '--column_buckets', 2, 'Wide row support.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_926000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Table.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_860000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Partition.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_170000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_sub_partition': ('-S', '--from_sub_partition', 'part_15', 'From sub-partition.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Partitioned_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_Subpartition_withHeader.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_585000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Sub_Partitioned_test_from', 'From table.'), 'from_passwd': ('-x', '--from_passwd', 'part_15_sp1', 'Exadata source user password.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_SubpartitionList.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_452000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_db_name': ('-b', '--from_db_name', 'part_15_sp1,part_15_sp2,part_14_sp1,part_14_sp2', 'Exadata source database.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Sub_Partitioned_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_TimestampTable_keepWhitespace_withHeader.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_237000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryFile_noHeader.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_869000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'query_sql_file': ('-q', '--query_sql_file', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\oracle_query.sql', 'Input file with Exadata query sql.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_ShardedQueryDir_withHeader.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_051000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'query_sql_dir': ('-Q', '--query_sql_dir', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\query_dir_ora', 'Input dir with Exadata query files sql.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_ShardedQueryDir.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_749000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'query_sql_dir': ('-Q', '--query_sql_dir', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\query_dir_ora', 'Input dir with Exadata query files sql.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Subpartition_Validate.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_179000', 'Timestamp (log_dir/job_name/timestamp).'), 'validate': ('-V', '--validate', 1, 'Check if source and target objects exist.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Sub_Partitioned_test_from', 'From table.'), 'from_passwd': ('-x', '--from_passwd', 'part_15_sp1', 'Exadata source user password.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_SubpartitionList.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_456000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_db_name': ('-b', '--from_db_name', 'part_15_sp1,part_15_sp2,part_14_sp1,part_14_sp2', 'Exadata source database.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Sub_Partitioned_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_DateTable_Email.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_811000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Date_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Parallel_ShardedTable.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 3, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_732000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Subpartition_withHeader.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_581000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Sub_Partitioned_test_from', 'From table.'), 'from_passwd': ('-x', '--from_passwd', 'part_15_sp1', 'Exadata source user password.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Table.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_865000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_ShardedSubpartition.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_628000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Sub_Partitioned_test_from', 'From table.'), 'from_passwd': ('-x', '--from_passwd', 'part_15_sp1', 'Exadata source user password.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryFile_withHeader.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_332000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'query_sql_file': ('-q', '--query_sql_file', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\oracle_query.sql', 'Input file with Exadata query sql.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryFile_keepWhitespace.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_216000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'query_sql_file': ('-q', '--query_sql_file', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\oracle_query.sql', 'Input file with Exadata query sql.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Partition.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_166000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_sub_partition': ('-S', '--from_sub_partition', 'part_15', 'From sub-partition.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Partitioned_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_TimestampTable_trimWhitespace.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_129000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_Subpartition_KeepSpoolFile.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_263000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Sub_Partitioned_test_from', 'From table.'), 'from_passwd': ('-x', '--from_passwd', 'part_15_sp1', 'Exadata source user password.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryDir.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_532000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'query_sql_dir': ('-Q', '--query_sql_dir', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\query_dir_ora', 'Input dir with Exadata query files sql.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryFile_keepWhitespace_noHeader.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_969000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'query_sql_file': ('-q', '--query_sql_file', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\oracle_query.sql', 'Input file with Exadata query sql.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_PartitionList.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_780000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'from_table': ('-c', '--from_table', 'SCOTT.Partitioned_test_from', 'From table.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_user': ('-j', '--from_user', 'part_13,part_14,part_15,part_16', 'Exadata source user.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_DateTable.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_384000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Date_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryFile_TableNamedFile.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_991000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'query_sql_file': ('-q', '--query_sql_file', '"C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\SCOTT.TIMESTAMP_TEST_TO.0.sql"', 'Input file with Exadata query sql.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryFile_TableNamedFile.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_001000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'query_sql_file': ('-q', '--query_sql_file', '"C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\SCOTT.TIMESTAMP_TEST_TO.0.sql"', 'Input file with Exadata query sql.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_Subpartition_WithWideRows.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'column_buckets': ('-0', '--column_buckets', 2, 'Wide row support.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_138000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Sub_Partitioned_test_from', 'From table.'), 'from_passwd': ('-x', '--from_passwd', 'part_15_sp1', 'Exadata source user password.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_TimezoneTable_KeepSpoolFile.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_424000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timezone_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_ShardedPartition.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_557000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_sub_partition': ('-S', '--from_sub_partition', 'part_15', 'From sub-partition.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Partitioned_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_Parallel_PartitionList.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 3, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_676000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'from_table': ('-c', '--from_table', 'SCOTT.Partitioned_test_from', 'From table.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_user': ('-j', '--from_user', 'part_13,part_14,part_15,part_16', 'Exadata source user.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_ShardedTimestampTable_keepWhitespace_Validate.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_519000', 'Timestamp (log_dir/job_name/timestamp).'), 'validate': ('-V', '--validate', 1, 'Check if source and target objects exist.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_Parallel_PartitionList.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 3, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_682000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'from_table': ('-c', '--from_table', 'SCOTT.Partitioned_test_from', 'From table.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_user': ('-j', '--from_user', 'part_13,part_14,part_15,part_16', 'Exadata source user.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_Partition_TruncateTarget_AskToTruncate.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'ask_to_truncate': ('-E', '--ask_to_truncate', 1, 'Ask to truncate.'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_373000', 'Timestamp (log_dir/job_name/timestamp).'), 'truncate_target': ('-U', '--truncate_target', 1, 'Truncate target table/partition/subpartition.'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'from_sub_partition': ('-S', '--from_sub_partition', 'part_15', 'From sub-partition.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Partitioned_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryDir_keepWhitespace.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_323000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'query_sql_dir': ('-Q', '--query_sql_dir', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\query_dir_ora', 'Input dir with Exadata query files sql.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryFile_trimWhitespace_noHeader.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_443000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'query_sql_file': ('-q', '--query_sql_file', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\oracle_query.sql', 'Input file with Exadata query sql.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_Subpartition_withHeader.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_590000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Sub_Partitioned_test_from', 'From table.'), 'from_passwd': ('-x', '--from_passwd', 'part_15_sp1', 'Exadata source user password.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_TimezoneTable_KeepSpoolFile.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_429000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timezone_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryFile_keepWhitespace.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_225000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'query_sql_file': ('-q', '--query_sql_file', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\oracle_query.sql', 'Input file with Exadata query sql.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'ORAEXA_QueryFile_WithWideRows.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'column_buckets': ('-0', '--column_buckets', 2, 'Wide row support.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_505000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'query_sql_file': ('-q', '--query_sql_file', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\oracle_query.sql', 'Input file with Exadata query sql.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_TimezoneQueryFile.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000655_241000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'query_sql_file': ('-q', '--query_sql_file', 'C:\\Python27\\data_migrator_1239_pscp\\test\\v101\\query\\oracle_query.sql', 'Input file with Exadata query sql.'), 'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_TimezoneTable.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_481000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timezone_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_ShardedTable.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'csv', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_608000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'ORAEXA_JSON_Table.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-ps', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'spool_type': ('-6', '--spool_type', 'json', 'Spool file type (CSV or JSON).'), 'copy_vector': ('-w', '--copy_vector', 'ORAEXA-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'default_spool_dir': ('-F', '--default_spool_dir', 'C:\\tmp\\TEST_default_spool', 'Default data dump dir (default_spool_dir/job_name/timestamp).'), 'time_stamp': ('-Y', '--time_stamp', '20160418_000654_665000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'header': ('-A', '--header', '"YYYY-MM-DD HH24.MI.SS"', 'Include header to Exadata extract.'), 'keep_whitespace': ('-W', '--keep_whitespace', '"YYYY-MM-DD HH24.MI.SS.FF2"', 'Keep whitespace from CHAR type in "Exadata" extract.'), 'nls_date_format': ('-e', '--nls_date_format', 'SCOTT', 'nls_date_format for source.'), 'nls_timestamp_format': ('-m', '--nls_timestamp_format', 'tiger', 'nls_timestamp_format for source.'), 'nls_timestamp_tz_format': ('-O', '--nls_timestamp_tz_format', 'orcl', 'nls_timestamp_tz_format for source.'), 'from_table': ('-c', '--from_table', 'SCOTT.Timestamp_test_from', 'From table.')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}]}