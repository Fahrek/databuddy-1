#do not change
aa={'CSV_Dirs_Limit10.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_252000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'input_dirs': ('-I', '--input_dirs', '.\\test\\v101\\data\\mongo_data_dir', 'Input CSV directory.'), 'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'CSV_DateFiles.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_351000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'input_files': ('-i', '--input_files', '.\\test\\v101\\data\\mongo_shard_0.data,.\\test\\v101\\data\\mongo_shard_0.data', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'CSV_Dirs_Limit10.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_254000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'input_dirs': ('-I', '--input_dirs', '.\\test\\v101\\data\\mongo_data_dir', 'Input CSV directory.'), 'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'CSV_TimestampFile.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_280000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'input_files': ('-i', '--input_files', '.\\test\\v101\\data\\mongo_shard_0.data', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'CSV_FileSkip1.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_332000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 100, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'skip_rows': ('-k', '--skip_rows', 1, 'Header size. Number of rows to skip in input file.'), 'input_files': ('-i', '--input_files', '.\\test\\v101\\data\\mongo_shard_0.data', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'CSV_DirsSkip1.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_370000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'input_dirs': ('-I', '--input_dirs', '.\\test\\v101\\data\\mongo_data_dir', 'Input CSV directory.'), 'skip_rows': ('-k', '--skip_rows', 1, 'Header size. Number of rows to skip in input file.'), 'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'CSV_ShardedDirSkip1.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_338000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'input_dirs': ('-I', '--input_dirs', '.\\test\\v101\\data\\mongo_data_dir', 'Input CSV directory.'), 'skip_rows': ('-k', '--skip_rows', 1, 'Header size. Number of rows to skip in input file.'), 'shard_size_kb': ('-y', '--shard_size_kb', 50, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'CSV_File.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_347000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'input_files': ('-i', '--input_files', '.\\test\\v101\\data\\mongo_shard_0.data', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'CSV_ShardedFileSkip1.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_272000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 10, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'skip_rows': ('-k', '--skip_rows', 1, 'Header size. Number of rows to skip in input file.'), 'input_files': ('-i', '--input_files', '.\\test\\v101\\data\\mongo_shard_0.data', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'CSV_Files_TableNamedFile.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_319000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'input_files': ('-i', '--input_files', '".\\test\\v101\\data\\SCOTT.Timestamp_test_to.data",".\\test\\v101\\data\\SCOTT.Timestamp_test_to_2.data"', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'CSV_Dir.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_321000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'input_dirs': ('-I', '--input_dirs', '.\\test\\v101\\data\\mongo_data_dir', 'Input CSV directory.'), 'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'CSV_Dirs.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_245000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'input_dirs': ('-I', '--input_dirs', '.\\test\\v101\\data\\mongo_data_dir', 'Input CSV directory.'), 'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'CSV_MongoFile.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_357000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'input_files': ('-i', '--input_files', '.\\test\\v101\\data\\oracle_shard_0_mongo.csv', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'CSV_File_TableNamedFile.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_261000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'input_files': ('-i', '--input_files', '".\\test\\v101\\data\\SCOTT.Timestamp_test_to.data"', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'CSV_TimezoneFile.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_287000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'input_files': ('-i', '--input_files', '.\\test\\v101\\data\\mongo_shard_0.data', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'CSV_File_Limit10.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_262000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'input_files': ('-i', '--input_files', '.\\test\\v101\\data\\mongo_shard_0.data', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'CSV_Dir.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_325000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'input_dirs': ('-I', '--input_dirs', '.\\test\\v101\\data\\mongo_data_dir', 'Input CSV directory.'), 'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'CSV_DateFile.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_275000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'input_files': ('-i', '--input_files', '.\\test\\v101\\data\\mongo_shard_0.data', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'CSV_TimezoneFile.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_290000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'input_files': ('-i', '--input_files', '.\\test\\v101\\data\\mongo_shard_0.data', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'CSV_ShardedDirSkip1.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_342000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'input_dirs': ('-I', '--input_dirs', '.\\test\\v101\\data\\mongo_data_dir', 'Input CSV directory.'), 'skip_rows': ('-k', '--skip_rows', 1, 'Header size. Number of rows to skip in input file.'), 'shard_size_kb': ('-y', '--shard_size_kb', 50, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'CSV_DateFile.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_277000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'input_files': ('-i', '--input_files', '.\\test\\v101\\data\\mongo_shard_0.data', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'CSV_File.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_343000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'input_files': ('-i', '--input_files', '.\\test\\v101\\data\\mongo_shard_0.data', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'CSV_TimestampFile.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_283000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'input_files': ('-i', '--input_files', '.\\test\\v101\\data\\mongo_shard_0.data', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'CSV_File.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_345000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'input_files': ('-i', '--input_files', '.\\test\\v101\\data\\mongo_shard_0.data', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'CSV_File_Limit10.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_267000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'input_files': ('-i', '--input_files', '.\\test\\v101\\data\\mongo_shard_0.data', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'CSV_Dir.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_323000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'input_dirs': ('-I', '--input_dirs', '.\\test\\v101\\data\\mongo_data_dir', 'Input CSV directory.'), 'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'CSV_ShardedDir_Limit10.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_328000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'input_dirs': ('-I', '--input_dirs', '.\\test\\v101\\data\\mongo_data_dir', 'Input CSV directory.'), 'shard_size_kb': ('-y', '--shard_size_kb', 50, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'CSV_ShardedDir_Limit10.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_330000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'input_dirs': ('-I', '--input_dirs', '.\\test\\v101\\data\\mongo_data_dir', 'Input CSV directory.'), 'shard_size_kb': ('-y', '--shard_size_kb', 50, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'CSV_DateFiles.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_352000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'input_files': ('-i', '--input_files', '.\\test\\v101\\data\\mongo_shard_0.data,.\\test\\v101\\data\\mongo_shard_0.data', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'CSV_DirsSkip1.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_372000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'input_dirs': ('-I', '--input_dirs', '.\\test\\v101\\data\\mongo_data_dir', 'Input CSV directory.'), 'skip_rows': ('-k', '--skip_rows', 1, 'Header size. Number of rows to skip in input file.'), 'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'CSV_DateFile.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_278000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'input_files': ('-i', '--input_files', '.\\test\\v101\\data\\mongo_shard_0.data', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'CSV_TimestampFile.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_285000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'input_files': ('-i', '--input_files', '.\\test\\v101\\data\\mongo_shard_0.data', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'CSV_Dirs.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_243000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'input_dirs': ('-I', '--input_dirs', '.\\test\\v101\\data\\mongo_data_dir', 'Input CSV directory.'), 'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'CSV_ShardedDir_Limit10.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_326000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'input_dirs': ('-I', '--input_dirs', '.\\test\\v101\\data\\mongo_data_dir', 'Input CSV directory.'), 'shard_size_kb': ('-y', '--shard_size_kb', 50, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'CSV_DirsSkip1.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_374000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'input_dirs': ('-I', '--input_dirs', '.\\test\\v101\\data\\mongo_data_dir', 'Input CSV directory.'), 'skip_rows': ('-k', '--skip_rows', 1, 'Header size. Number of rows to skip in input file.'), 'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'CSV_File_TableNamedFile.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_257000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'input_files': ('-i', '--input_files', '".\\test\\v101\\data\\SCOTT.Timestamp_test_to.data"', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'CSV_File_TableNamedFile.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_259000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'input_files': ('-i', '--input_files', '".\\test\\v101\\data\\SCOTT.Timestamp_test_to.data"', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'CSV_ShardedFile_Limit10.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_362000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 10, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'input_files': ('-i', '--input_files', '.\\test\\v101\\data\\mongo_shard_0.data', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'CSV_ShardedFile.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_247000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 10, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'input_files': ('-i', '--input_files', '.\\test\\v101\\data\\mongo_shard_0.data', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'CSV_FileSkip1.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_335000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 100, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'skip_rows': ('-k', '--skip_rows', 1, 'Header size. Number of rows to skip in input file.'), 'input_files': ('-i', '--input_files', '.\\test\\v101\\data\\mongo_shard_0.data', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'CSV_DateFiles.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_349000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'input_files': ('-i', '--input_files', '.\\test\\v101\\data\\mongo_shard_0.data,.\\test\\v101\\data\\mongo_shard_0.data', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'CSV_MongoFile.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_354000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'input_files': ('-i', '--input_files', '.\\test\\v101\\data\\oracle_shard_0_mongo.csv', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'default': [{'ask_to_truncate': ['-E', '--ask_to_truncate', '', 'Ask to truncate.'], 'shard_pre_etl': ['-2', '--shard_pre_etl', '', 'Path to shard level pre-ETL Python script.'], 'debug_level': ['-dbg', '--debug_level', '', 'QC Debug level.'], 'spool_type': ['-6', '--spool_type', '', 'Spool file type (CSV or JSON).'], 'keep_data_file': ['-K', '--keep_data_file', '', 'Keep data dump.'], 'default_spool_dir': ['-F', '--default_spool_dir', '', 'Default data dump dir (default_spool_dir/job_name/timestamp).'], 'lame_duck': ['-l', '--lame_duck', '', 'Limit rows (lame duck run).'], 'copy_vector': ['-w', '--copy_vector', '', 'Data copy direction.'], 'log_dir': ['-M', '--log_dir', '', 'Log destination.'], 'time_stamp': ['-Y', '--time_stamp', '', 'Timestamp (log_dir/job_name/timestamp).'], 'job_name': ['-B', '--job_name', '', 'Job name (log_dir/job_name).'], 'status_pipe_id': ['-spID', '--status_pipe_id', '', 'Status reporting pipe ID.'], 'job_pre_etl': ['-1', '--job_pre_etl', '', 'Path to job level pre-ETL Python script.'], 'num_of_shards': ['-r', '--num_of_shards', '', 'Number of shards.'], 'loader_profile': ['-C', '--loader_profile', '', 'SQL*Loader profile (user defined).'], 'email_to': ['-L', '--email_to', '', 'Email job status.'], 'host_map': ['-5', '--host_map', '', 'Host-to-shard map.'], 'validate': ['-V', '--validate', '', 'Check if source and target objects exist.'], 'field_term': ['-t', '--field_term', '', 'Field terminator.'], 'pool_size': ['-o', '--pool_size', '', 'Pool size.'], 'column_buckets': ['-0', '--column_buckets', '', 'Wide row support.'], 'job_post_etl': ['-3', '--job_post_etl', '', 'Jobs post-etl script.'], 'truncate_target': ['-U', '--truncate_target', '', 'Truncate target table/partition/subpartition.'], 'shard_post_etl': ['-4', '--shard_post_etl', '', 'Shards post-etl script.'], 'key_on_exit': ['-X', '--key_on_exit', '', 'Ask for an "Enter" key upon exit.']}, {'input_dirs': ['-I', '--input_dirs', '', 'Input CSV directory.'], 'shard_size_kb': ['-y', '--shard_size_kb', '', 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'], 'skip_rows': ['-k', '--skip_rows', '', 'Header size. Number of rows to skip in input file.'], 'input_files': ['-i', '--input_files', '', 'Input CSV file(s).']}, {'to_db_name': ['-d', '--to_db_name', '', 'MongoDB database.'], 'to_db_port': ['-T', '--to_db_port', '', 'Target MongoDB port.'], 'to_column_names': ['-Z', '--to_column_names', '', 'To column list for MongoDB.'], 'to_collection': ['-a', '--to_collection', '', 'To table.'], 'to_user': ['-u', '--to_user', '', 'Target MongoDB db user.'], 'to_passwd': ['-p', '--to_passwd', '', 'MongoDB user password.'], 'to_db_server': ['-s', '--to_db_server', '', 'Target MongoDB instance name.'], 'numInsertionWorkers': ['-numIW', '--numInsertionWorkers', '', 'Upsert rows into MongoDB.'], 'upsert': ['-G', '--upsert', '', 'Upsert rows into MongoDB.']}], 'CSV_File_Limit10.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_264000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'input_files': ('-i', '--input_files', '.\\test\\v101\\data\\mongo_shard_0.data', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'CSV_ShardedDir.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_367000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'input_dirs': ('-I', '--input_dirs', '.\\test\\v101\\data\\mongo_data_dir', 'Input CSV directory.'), 'shard_size_kb': ('-y', '--shard_size_kb', 50, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'CSV_ShardedFile.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_250000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 10, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'input_files': ('-i', '--input_files', '.\\test\\v101\\data\\mongo_shard_0.data', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'CSV_Files_TableNamedFile.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_292000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'input_files': ('-i', '--input_files', '".\\test\\v101\\data\\SCOTT.Timestamp_test_to.data",".\\test\\v101\\data\\SCOTT.Timestamp_test_to_2.data"', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'CSV_MongoFile.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_358000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'input_files': ('-i', '--input_files', '.\\test\\v101\\data\\oracle_shard_0_mongo.csv', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'CSV_Files_TableNamedFile.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_318000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'input_files': ('-i', '--input_files', '".\\test\\v101\\data\\SCOTT.Timestamp_test_to.data",".\\test\\v101\\data\\SCOTT.Timestamp_test_to_2.data"', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'CSV_ShardedFileSkip1.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_268000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 10, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'skip_rows': ('-k', '--skip_rows', 1, 'Header size. Number of rows to skip in input file.'), 'input_files': ('-i', '--input_files', '.\\test\\v101\\data\\mongo_shard_0.data', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'CSV_ShardedDirSkip1.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_340000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'input_dirs': ('-I', '--input_dirs', '.\\test\\v101\\data\\mongo_data_dir', 'Input CSV directory.'), 'skip_rows': ('-k', '--skip_rows', 1, 'Header size. Number of rows to skip in input file.'), 'shard_size_kb': ('-y', '--shard_size_kb', 50, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'CSV_ShardedFile.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_248000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 10, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'input_files': ('-i', '--input_files', '.\\test\\v101\\data\\mongo_shard_0.data', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'CSV_FileSkip1.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_336000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 100, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'skip_rows': ('-k', '--skip_rows', 1, 'Header size. Number of rows to skip in input file.'), 'input_files': ('-i', '--input_files', '.\\test\\v101\\data\\mongo_shard_0.data', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'CSV_ShardedDir.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_368000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'input_dirs': ('-I', '--input_dirs', '.\\test\\v101\\data\\mongo_data_dir', 'Input CSV directory.'), 'shard_size_kb': ('-y', '--shard_size_kb', 50, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'CSV_Dirs_Limit10.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_255000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'input_dirs': ('-I', '--input_dirs', '.\\test\\v101\\data\\mongo_data_dir', 'Input CSV directory.'), 'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'CSV_ShardedDir.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_365000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'input_dirs': ('-I', '--input_dirs', '.\\test\\v101\\data\\mongo_data_dir', 'Input CSV directory.'), 'shard_size_kb': ('-y', '--shard_size_kb', 50, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}], 'CSV_TimezoneFile.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 1, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_288000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 1000, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'input_files': ('-i', '--input_files', '.\\test\\v101\\data\\mongo_shard_0.data', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'CSV_ShardedFile_Limit10.MONGO_Collection_3_insertionWorkers': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_363000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 10, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'input_files': ('-i', '--input_files', '.\\test\\v101\\data\\mongo_shard_0.data', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 3, 'Upsert rows into MongoDB.')}], 'CSV_ShardedFileSkip1.MONGO_Collection': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_270000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 10, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'skip_rows': ('-k', '--skip_rows', 1, 'Header size. Number of rows to skip in input file.'), 'input_files': ('-i', '--input_files', '.\\test\\v101\\data\\mongo_shard_0.data', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.')}], 'CSV_ShardedFile_Limit10.MONGO_Collection_Upsert': [{'lame_duck': ('-l', '--lame_duck', 10, 'Limit rows (lame duck run).'), 'field_term': ('-t', '--field_term', '"|"', 'Field terminator.'), 'num_of_shards': ('-r', '--num_of_shards', 3, 'Number of shards.'), 'pool_size': ('-o', '--pool_size', 1, 'Pool size.'), 'debug_level': ('-dbg', '--debug_level', 1, 'QC Debug level.'), 'copy_vector': ('-w', '--copy_vector', 'CSV-MONGO', 'Data copy direction.'), 'keep_data_file': ('-K', '--keep_data_file', 1, 'Keep data dump.'), 'time_stamp': ('-Y', '--time_stamp', '20150707_191113_360000', 'Timestamp (log_dir/job_name/timestamp).'), 'host_map': ('-5', '--host_map', '".\\config\\host_map\\host_map.py"', 'Host-to-shard map.'), 'job_name': ('-B', '--job_name', 'qc_job', 'Job name (log_dir/job_name).'), 'log_dir': ('-M', '--log_dir', 'C:\\Temp\\qc_log', 'Log destination.')}, {'shard_size_kb': ('-y', '--shard_size_kb', 10, 'Shard size in KBytes (to partition file and to estimate number of lines in input CSV file).'), 'input_files': ('-i', '--input_files', '.\\test\\v101\\data\\mongo_shard_0.data', 'Input CSV file(s).')}, {'to_db_name': ('-d', '--to_db_name', 'test', 'MongoDB database.'), 'to_db_port': ('-T', '--to_db_port', '27017', 'Target MongoDB port.'), 'to_column_names': ('-Z', '--to_column_names', '"ID,TITLE,ISIN,COUNTRY,DESCRIPTION,SECURITYTYPE,CREATED"', 'To column list for MongoDB.'), 'to_collection': ('-a', '--to_collection', 'test', 'To table.'), 'to_user': ('-u', '--to_user', 'test_user', 'Target MongoDB db user.'), 'to_passwd': ('-p', '--to_passwd', 'tast_pwd', 'MongoDB user password.'), 'to_db_server': ('-s', '--to_db_server', 'localhost', 'Target MongoDB instance name.'), 'numInsertionWorkers': ('-numIW', '--numInsertionWorkers', 1, 'Upsert rows into MongoDB.'), 'upsert': ('-G', '--upsert', 1, 'Upsert rows into MongoDB.')}]}